{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c3a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('', '...')))  \n",
    "# Import the required modules\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import h5py\n",
    "import json\n",
    "import argparse\n",
    "from functions.system.limbNetwork import limbNetwork\n",
    "from functions.controller import controllerFuncs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e97286",
   "metadata": {},
   "source": [
    "## Here we will define the simulation parameters \n",
    "\n",
    "This involves \n",
    "1. loading the saved random network (adjacency matrix and readout weights)\n",
    "2. setting the task parameters such as time for preparation and movement, and the penalties on different system states\n",
    "3. setting up cost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2481bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## load Radnomly initialized networks from the hdf5 files ##########\n",
    "def load_networks_by_spectral_radius(args):\n",
    "    filename = args.filename\n",
    "    spectral_radius = args.spectral_radiuses[0] + 0\n",
    "    networks = []\n",
    "    readouts = []\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        spectral_radius_group = str(spectral_radius)  # Ensure the spectral radius is in the correct format\n",
    "        if spectral_radius_group in f:\n",
    "            for i in range(10):  # Assuming there are always 10 networks\n",
    "                network_dataset_name = f'{spectral_radius_group}/networks/network_{i}'\n",
    "                readout_dataset_name = f'{spectral_radius_group}/readouts/readout_{i}'\n",
    "                if network_dataset_name in f:\n",
    "                    network = f[network_dataset_name][()]\n",
    "                    networks.append(network)\n",
    "\n",
    "                    readout = f[readout_dataset_name][()]\n",
    "                    readouts.append(readout)\n",
    "                else:\n",
    "                    print(f\"Dataset {network_dataset_name} not found.\")\n",
    "        else:\n",
    "            print(f\"Spectral radius group {spectral_radius_group} not found.\")\n",
    "    return networks, readouts\n",
    "\n",
    "\n",
    "######## set simulation and cost parameters #############\n",
    "def setsimparams():\n",
    "    k = 0.1\n",
    "    m = 1\n",
    "    tau = 0.06\n",
    "    delta = 1e-2\n",
    "    rtime = 1.0\n",
    "    prep_time = 1.0\n",
    "    \n",
    "    \n",
    "\n",
    "    num_neurons = 100\n",
    "    nStep = int(np.round((rtime + prep_time)/delta))\n",
    "    nPrep = int(np.round(prep_time/delta))\n",
    "    # the cost can penalize froma given end time, or throughout the reach period\n",
    "    nTerminal = int((nStep - nPrep) / 2) # Use terinal time as OPTIONAL if the movement must end at a specific time\n",
    "    nHold = 0\n",
    "    w = np.zeros(shape=(8+num_neurons+1, nStep-nPrep+1))\n",
    "\n",
    "\n",
    "\n",
    "    ##### COST PARAMETERS WITH TAU_NET on THE B MATRIX #######\n",
    "    state_alpha = 100 \n",
    "    prep_alpha = 100\n",
    "    effort_alpha = 1e-13\n",
    "    \n",
    "    # total execution period lasts 1 second (rtime). But set the terminal time step as 500 ms (0.5s) where the hand must be on the target with zero velocity\n",
    "    # we will use a high cost on the position (10) and relatively low cost on velocity (0.1) at the terminal time\n",
    "    \n",
    "\n",
    "    # TERMINAL COSTS: cost after terminal time until the end of the reach period. the hand must be stable on the target.\n",
    "    # we can use the same penalties as before for position and velocity costs\n",
    "    #for t in range(nTerminal, nStep-nPrep):\n",
    "    #    w[:8, t] = (1/nTerminal) * np.array([1, .1, 0, 0, 1, .1, 0, 0]) #* ((t) / (nStep - nPrep))**6\n",
    "\n",
    "    # COST PARAMETERS WITH HIGHER EXPONENTIAL (i.e. giving more importance to terminal position errors) #######\n",
    "    for t in range(0, nStep-nPrep):\n",
    "        w[:8, t] = (1/nStep) * np.array([100, 0.0, 0.000, 0, 100, 0.0, 0.000, 0])  * ((t) / (nStep - nPrep))**6\n",
    "\n",
    "    wprep = np.zeros(shape=(8+num_neurons+1, nPrep+1))\n",
    "    for t in range(0, nPrep+1):\n",
    "        wprep[:8, t] = (1/nStep) * np.array([100, 1, 1, 0, 100, 1, 1, 0]) \n",
    "\n",
    "\n",
    "    ##### COST PARAMETERS WITH smaller exponential (i.e. giving importance to continuous position errors instead of terminal position) #######\n",
    "    prep_alpha = 100\n",
    "    effort_alpha = 1e-13 \n",
    "    for t in range(0, nStep-nPrep):\n",
    "        w[:8, t] = (1/nStep) * np.array([1, 0, 0, 0, 1, 0, 0, 0]) * ((t) / (nStep - nPrep))**2\n",
    "    wprep = np.zeros(shape=(8+num_neurons+1, nPrep+1))\n",
    "    for t in range(0, nPrep+1):\n",
    "        wprep[:8, t] = (1/nStep) * prep_alpha * np.array([1, 1, 1, 0, 1, 1, 1, 0])\n",
    "    r = effort_alpha + 0.0\n",
    "\n",
    "\n",
    "\n",
    "    #wprep = np.zeros(shape=(8+num_neurons+1, nPrep+1))\n",
    "    #for t in range(0, nPrep+1):\n",
    "    #    wprep[:8, t] = (1/nStep) * prep_alpha * np.array([1, 1, 1, 0, 1, 1, 1, 0])\n",
    "    r = effort_alpha + 0.0\n",
    "\n",
    "\n",
    "    simparams = {'k': k, 'm': m, 'tau': tau, \n",
    "              'delta': delta, 'rtime': rtime, 'prep_time': prep_time, 'nStep': nStep, 'r': r, \n",
    "              'w': w, \n",
    "              'num_neurons': num_neurons, 'nPrep': nPrep, 'wprep': wprep, 'neuron_tau_net': 20e-3}\n",
    "    \n",
    "    return simparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f003f5a",
   "metadata": {},
   "source": [
    "#### define the function to simulate the reaching control task to 8 different targets ###########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d40f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reach8dir(params):\n",
    "    # GET body matrices and SET cost matrices\n",
    "    system_dynamics = limbNetwork(params)\n",
    "    Atot, Btot, Htot = system_dynamics.getSystemMatrices()\n",
    "    #R, Q = setCostmatrices(Atot, Btot, params['delta'], params['r'], params['w']) # cross-checked the R, Q with Fred's code. They are the same\n",
    "    #R, Q = setCostmatrices_wprep(Atot, Btot, params['delta'], params['r'], params['w'], params['wprep'], params['nPrep']) # cross-checked the R, Q with Fred's code. They are the same\n",
    "\n",
    "    # By this point, we have the system matrices (Atot,Btot) and the cost matrices (R,Q). Now we need to compute the feedback gains L.\n",
    "    # For this, we need to compute the noise covariance matrix SigmaXi. We will use the same noise covariance matrix as Fred's code.\n",
    "    # The noise covariance matrix is defined as follows:\n",
    "    SigmaXi = system_dynamics.SigmaXi + 0.0\n",
    "    SigmaOmega = system_dynamics.SigmaOmega + 0.0\n",
    "\n",
    "    R, Q = controllerFuncs.setCostmatrices_wprep_MPC(Atot, Btot, params['delta'], params['r'], params['w'], params['wprep'], params['nPrep'])\n",
    "    L = controllerFuncs.basicLQG(Atot, Btot, Q, R, SigmaXi)\n",
    "    K = controllerFuncs.basicKalman(Atot, Btot, Q, R, Htot, SigmaXi, SigmaOmega)\n",
    "\n",
    "    system_dynamics.SigmaXi[3,3] = 0                 # X force trick\n",
    "    SigmaXi[3, 3] = 0                 # X force trick\n",
    "    system_dynamics.SigmaXi[7,7] = 0                 # Y force trick\n",
    "    SigmaXi[7, 7] = 0                 # Y force trick\n",
    "\n",
    "    # Now we have the feedback gains L. We can use this to simulate the system.\n",
    "    # For this, we need to define the simulation time and the target parameters\n",
    "    simtime = np.arange(0, params['rtime']+params['prep_time'] + params['delta'], params['delta'])\n",
    "    num_targconditions = 8\n",
    "    num_states = (params['num_neurons'] + 1 + 8) * 3\n",
    "    num_controls = params['num_neurons']\n",
    "    num_steps = len(simtime)\n",
    "    all_states = np.zeros((num_steps, num_targconditions, num_states))\n",
    "    all_estimates = np.zeros((num_steps, num_targconditions, num_states))\n",
    "    all_controls = np.zeros((num_steps, num_targconditions, num_controls))\n",
    "    all_innovation = np.zeros((num_steps, num_targconditions, num_states))\n",
    "    \n",
    "    # targets location is in the indices 8 and 12 for X and Y respectively\n",
    "    # so for 8 targ conditions, we will use radial targets at 5 cm from origin in 8 directions from 0 to 360 degrees\n",
    "    # the target states are defined as follows:\n",
    "    target_states = np.zeros((num_targconditions, num_states))\n",
    "    target_states[:, 8 + params['num_neurons'] + 1] = 0.2*np.cos(np.arange(0, 2*np.pi, 2*np.pi/num_targconditions))   # X\n",
    "    target_states[:, 12 + params['num_neurons'] + 1] = 0.2 * np.sin(np.arange(0, 2*np.pi, 2*np.pi/num_targconditions))  # Y\n",
    "\n",
    "    # target states for preparation\n",
    "    prep_states = np.zeros((num_targconditions, num_states))\n",
    "    prep_states[:, 2 * (8 + params['num_neurons'] + 1)] = 0.0   # X\n",
    "    prep_states[:, 2 * (8 + params['num_neurons'] + 1) + 4] = 0.0   # X\n",
    "\n",
    "    # the target states are active for the entire simulation time\n",
    "    # so the all_states matrix will have the target states repeated for all time steps\n",
    "    all_states[:, :, 8 + params['num_neurons'] + 1] = target_states[:, 8 +params['num_neurons'] + 1].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_states[:, :, 12 + params['num_neurons'] + 1] = target_states[:, 12 + params['num_neurons'] + 1].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_states[:, :, 2 * (8 + params['num_neurons'] + 1)] = prep_states[:, 2 * (8 + params['num_neurons'] + 1)].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_states[:, :, 2 * (8 + params['num_neurons'] + 1) + 4] = prep_states[:, 2 * (8 + params['num_neurons'] + 1) + 4].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_estimates[:, :, 8 + params['num_neurons'] + 1] = target_states[:, 8 + params['num_neurons'] + 1].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_estimates[:, :, 12 + params['num_neurons'] + 1] = target_states[:, 12 + params['num_neurons'] + 1].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_estimates[:, :, 2 * (8 + params['num_neurons'] + 1)] = prep_states[:, 2 * (8 + params['num_neurons'] + 1)].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_estimates[:, :, 2 * (8 + params['num_neurons'] + 1) + 4] = prep_states[:, 2 * (8 + params['num_neurons'] + 1) + 4].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "\n",
    "    # set the desired offset states as 1 for the preparatory and actual target states\n",
    "    all_states[:, :, 8 + params['num_neurons']] = 1.0\n",
    "    all_states[:, :, 2*(8 + params['num_neurons'])] = 0.0\n",
    "    all_states[:, :, 3*(8 + params['num_neurons'])] = 0.0\n",
    "    all_estimates[:, :, 8 + params['num_neurons']] = 1.0\n",
    "    all_estimates[:, :, 2*(8 + params['num_neurons'])] = 0.0\n",
    "    all_estimates[:, :, 3*(8 + params['num_neurons'])] = 0.0\n",
    "\n",
    "\n",
    "    #\n",
    "    for i in range(num_targconditions):\n",
    "        system_dynamics.reset(all_states[0, i, :])\n",
    "        print('target number', i)\n",
    "        for t in range(num_steps-1):\n",
    "            # apply mechanical perturbation lateral (OPTIONAL)\n",
    "            if t >= params['nPrep'] + 10 and  t  <= params['nPrep'] + 20   and i == 2:\n",
    "                system_dynamics.states[3] = 0 # setting a non-zero value applies external perturbation for 100 ms \n",
    "\n",
    "            current_state = all_states[t, i, :] + 0.0\n",
    "            current_estimate = all_estimates[t, i, :] + 0.0\n",
    "\n",
    "            if t < params['nPrep']:\n",
    "                # apply control based on current estimate\n",
    "                current_control = -L[0, :, :] @ current_state\n",
    "            else:\n",
    "                current_control = -L[t - params['nPrep'], :, :] @ current_state\n",
    "            \n",
    "\n",
    "            all_controls[t, i, :] = current_control + 0.0\n",
    "\n",
    "\n",
    "            ## MPC method to recompute the control gains at each time step\n",
    "            #if t < num_steps - 40:\n",
    "            #    L = mixedLQG(Atot, Btot, Q[t:t+40, :, :], R[t:t+40, :, :], SigmaXi, params['nPrep'])\n",
    "            #else:\n",
    "            #    L = mixedLQG(Atot, Btot, Q[t:num_steps, :, :], R[t:num_steps, :, :], SigmaXi, params['nPrep'])\n",
    "\n",
    "            #update the estimate\n",
    "            #next_estimate, next_innovation = bodyins.nextEstimate(K[t, :, :], current_control)\n",
    "            # update the state\n",
    "            nextState = system_dynamics.nextState(current_control)\n",
    "        \n",
    "        \n",
    "            all_states[t+1, i, :] = nextState + 0.0\n",
    "            all_estimates[t+1, i, :] = nextState + 0.0\n",
    "            #all_innovation[t+1, i, :] = next_innovation + 0.0\n",
    "    \n",
    "    results = {}\n",
    "    results['states'] = all_states\n",
    "    results['estimates'] = all_estimates\n",
    "    results['controls'] = all_controls\n",
    "    results['innovations'] = all_innovation\n",
    "    results['L'] = L\n",
    "    results['K'] = K\n",
    "    results['Atot'] = Atot\n",
    "    results['Btot'] = Btot\n",
    "    results['bodyins'] = system_dynamics\n",
    "    results['Htot'] = Htot\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfddb7a",
   "metadata": {},
   "source": [
    "#### Function to run simulation of an 8 target reaching task once #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c74d4fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## function to run multiple simulations of the reach task based on user input (single or batch runs) ##########\n",
    "def run_simulation(args):\n",
    "    spectral_radius = args.spectral_radiuses[0]\n",
    "    networks, readouts = load_networks_by_spectral_radius(args)\n",
    "    network_id = args.network_id + 0\n",
    "\n",
    "    simparams_normal = setsimparams()\n",
    "    \n",
    "    \n",
    "    network = networks[network_id]\n",
    "    readout = readouts[network_id]\n",
    "    networkparams = {}\n",
    "    networkparams['Wrec'] = network\n",
    "    networkparams['Wout'] = readout\n",
    "    networkparams['spectral_radius'] = spectral_radius\n",
    "    networkparams['network_id'] = network_id\n",
    "\n",
    "    networkparams['Win'] = np.zeros((networkparams['Wrec'].shape[0], 8))\n",
    "    S = 8\n",
    "    N = networkparams['Wrec'].shape[0]\n",
    "\n",
    "    simparams_normal.update(networkparams)\n",
    "    \n",
    "\n",
    "    # run the simulations\n",
    "    results_8dir = reach8dir(simparams_normal)\n",
    "    \n",
    "    return results_8dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f298c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## function to save the results in a new hdf5 file ##########\n",
    "def save_results_to_hdf5(filename, results_8dir, args):\n",
    "    spectral_radius = args.spectral_radiuses[0]\n",
    "    i = args.network_id + 0\n",
    "    with h5py.File(filename, 'a') as f:\n",
    "        group = f.require_group(str(spectral_radius))\n",
    "        network_group = group.require_group(f'network_{i}')\n",
    "        res_group = network_group.require_group('results_8dir')\n",
    "\n",
    "        for key, value in results_8dir.items():\n",
    "            # If dataset already exists, delete it so we can overwrite\n",
    "            if key in res_group:\n",
    "                del res_group[key]\n",
    "\n",
    "            # Save numpy arrays directly\n",
    "            if isinstance(value, np.ndarray):\n",
    "                res_group.create_dataset(key, data=value)\n",
    "                continue\n",
    "\n",
    "            # Save basic scalars/strings directly\n",
    "            if isinstance(value, (int, float, bool, str, bytes)):\n",
    "                res_group.create_dataset(key, data=value)\n",
    "                continue\n",
    "\n",
    "            # Try pickling arbitrary Python objects and store as bytes\n",
    "            try:\n",
    "                pickled = pickle.dumps(value)\n",
    "                dt = h5py.special_dtype(vlen=bytes)\n",
    "                res_group.create_dataset(key, data=pickled, dtype=dt)\n",
    "            except Exception:\n",
    "                # If it still can't be saved, skip with a warning (e.g., large/unpicklable objects like live class instances)\n",
    "                print(f\"Skipping {key}: unsupported type {type(value)} (not saved)\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74c9849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109, 109) (109, 100)\n",
      "target number 0\n",
      "target number 1\n",
      "target number 2\n",
      "target number 3\n",
      "target number 4\n",
      "target number 5\n",
      "target number 6\n",
      "target number 7\n",
      "Skipping bodyins: unsupported type <class 'functions.system.limbNetwork.limbNetwork'> (not saved)\n"
     ]
    }
   ],
   "source": [
    "########## MAIN function that runs the task simulations (this example script runs one random newtork) ##########\n",
    "\n",
    "##___________________To use the inhibitory stabilized network structure use the following args___________##\n",
    "parser = argparse.ArgumentParser(description='Generate ISN neural networks with different spectral radiuses and save them to a HDF5 file.')\n",
    "parser.add_argument('--filename', type=str, default = 'isn_networks.hdf5', help='The HDF5 file to save the networks to.')\n",
    "\n",
    "#_________define the spectral radius or variance parameter for random connectivity___________#\n",
    "# CAUTION: Note that for denseRNNs, although we call this parameter as spectral_radiuses, it is actually the variance scaling factor 'g'\n",
    "# If using denseRNNs, set this value to 0.8 to load from existing datastore files\n",
    "parser.add_argument('--spectral_radiuses', type=float, nargs='+', default=[0.3], help='The spectral radiuses of the networks.')\n",
    "\n",
    "parser.add_argument('--seed', type=int, default=0, help='The seed for the random number generator.')\n",
    "parser.add_argument('--network_id', type=int, default=0, help='The ID of the network to run the simulation for.')\n",
    "parser.add_argument('--neural_effort_scaling', type=int, default=1e-12, help='The neural effort level. 1 for low, 2 for high.')\n",
    "# In a Jupyter notebook avoid parsing kernel args: use empty list to get defaults\n",
    "args = parser.parse_args([])\n",
    "# the file should be in the data store directory above the current directory\n",
    "# use only the basename from the provided filename to avoid accidental absolute paths\n",
    "args.filename = os.path.join('datastore', 'WeightsData', 'ISN', os.path.basename(args.filename))\n",
    "args.neural_effort_scaling = 1\n",
    "store_data_filename = 'datastore/SimulationData/8dirreach_task/denseRNN/denseRNN_results_singlesimulation.hdf5'\n",
    "\n",
    "\n",
    "##___________________To use the dense RNN without any inhibitory stabilized network structure use the following args___________##\n",
    "#parser = argparse.ArgumentParser(description='Generate dense neural networks with different spectral radiuses and save them to a HDF5 file.')\n",
    "#parser.add_argument('--filename', type=str, default = 'dense_network_weights.hdf5', help='The HDF5 file to save the networks to.')\n",
    "\n",
    "##_________define the spectral radius or variance parameter for random connectivity___________#\n",
    "## CAUTION: Note that for denseRNNs, although we call this parameter as spectral_radiuses, it is actually the variance scaling factor 'g'\n",
    "### If using denseRNNs, set this value to 0.8 to load from existing datastore files\n",
    "#parser.add_argument('--spectral_radiuses', type=float, nargs='+', default=[0.8], help='The spectral radiuses of the networks.')\n",
    "\n",
    "#parser.add_argument('--seed', type=int, default=0, help='The seed for the random number generator.')\n",
    "#parser.add_argument('--network_id', type=int, default=0, help='The ID of the network to run the simulation for.')\n",
    "#parser.add_argument('--neural_effort_scaling', type=int, default=1e-12, help='The neural effort level. 1 for low, 2 for high.')\n",
    "## In a Jupyter notebook avoid parsing kernel args: use empty list to get defaults\n",
    "#args = parser.parse_args([])\n",
    "## the file should be in the data store directory above the current directory\n",
    "## use only the basename from the provided filename to avoid accidental absolute paths\n",
    "#args.filename = os.path.join('datastore', 'WeightsData', 'denseRNN', os.path.basename(args.filename))\n",
    "#args.neural_effort_scaling = 1\n",
    "#store_data_filename = 'datastore/SimulationData/8dirreach_task/denseRNN/denseRNN_results_singlesimulation.hdf5'\n",
    "\n",
    "\n",
    "\t\n",
    "# Run a single simulation\n",
    "args.network_id = 0\n",
    "results_8dir = run_simulation(args)\n",
    "# pass the results and args to the save function (correct argument order)\n",
    "save_results_to_hdf5(store_data_filename, results_8dir, args)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b01b8fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.spectral_radiuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8bbb75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

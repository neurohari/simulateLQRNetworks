{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38c3a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('', '...')))  \n",
    "# Import the required modules\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import h5py\n",
    "import json\n",
    "import argparse\n",
    "from functions.system.limbNetwork import limbNetwork_modifieddynamics\n",
    "from functions.controller import controllerFuncs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e97286",
   "metadata": {},
   "source": [
    "## Here we will define the simulation parameters \n",
    "\n",
    "This involves \n",
    "1. loading the saved random network (adjacency matrix and readout weights)\n",
    "2. setting the task parameters such as time for preparation and movement, and the penalties on different system states\n",
    "3. setting up cost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b2481bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## load Radnomly initialized networks from the hdf5 files ##########\n",
    "def load_networks_by_spectral_radius(args):\n",
    "    filename = args.filename\n",
    "    spectral_radius = args.spectral_radiuses[0] + 0\n",
    "    networks = []\n",
    "    readouts = []\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        spectral_radius_group = str(spectral_radius)  # Ensure the spectral radius is in the correct format\n",
    "        if spectral_radius_group in f:\n",
    "            for i in range(10):  # Assuming there are always 10 networks\n",
    "                network_dataset_name = f'{spectral_radius_group}/networks/network_{i}'\n",
    "                readout_dataset_name = f'{spectral_radius_group}/readouts/readout_{i}'\n",
    "                if network_dataset_name in f:\n",
    "                    network = f[network_dataset_name][()]\n",
    "                    networks.append(network)\n",
    "\n",
    "                    readout = f[readout_dataset_name][()]\n",
    "                    readouts.append(readout)\n",
    "                else:\n",
    "                    print(f\"Dataset {network_dataset_name} not found.\")\n",
    "        else:\n",
    "            print(f\"Spectral radius group {spectral_radius_group} not found.\")\n",
    "    return networks, readouts\n",
    "\n",
    "\n",
    "################# define simulation parameters #####################\n",
    "def setsimparams(forcefield_param, inertial_param):\n",
    "    k = 0.1\n",
    "    m = 1\n",
    "    tau = 0.06\n",
    "    delta = 0.01\n",
    "    rtime = 0.4\n",
    "    prep_time = 1.0\n",
    "\n",
    "    num_neurons = 100\n",
    "    nStep = int(np.round((rtime + prep_time)/delta))\n",
    "    nPrep = int(np.round(prep_time/delta))\n",
    "    nHold = 0\n",
    "    w_normaldyn = np.zeros(shape=(8+num_neurons+1, nStep-nPrep+1))\n",
    "    w_ffdyn = np.zeros(shape=(8+num_neurons+1, nStep-nPrep+1))\n",
    "\n",
    "    \n",
    "\n",
    "    #### COSTS parameters by including the neuron_tau_net in B matrix ########\n",
    "    prep_alpha = 1e3\n",
    "    effort_alpha = 1e-12\n",
    "\n",
    "\n",
    "    for t in range(0, nStep - nPrep):\n",
    "        # The cost penalizes position errors heavily, velocity lightly, and forces very lightly (PLAY AROUND WITH PARAMS, SOLUTIONS ARE SIMILAR ACROSS A BROAD RANGE)\n",
    "        # (t / T)**6 makes the cost at the start of the movement very small, increasing to full cost at the end of movement (OPTIONAL)\n",
    "        w_ffdyn[:8, t] = (1/(nStep-nHold)) * np.array([10, 0.1, 0.0001, 0, 10, 0.1, 0.0001, 0]) * ((t) / (nStep - nPrep))**6\n",
    "\n",
    "\n",
    "    wprep = np.zeros(shape=(8+num_neurons+1, nPrep+1))\n",
    "    for t in range(0, nPrep+1):\n",
    "        wprep[:8, t] = (1/nStep) * np.array([1000, 10, 0, 0, 1000, 10, 0, 0]) \n",
    "\n",
    "    r = effort_alpha + 0.0\n",
    "\n",
    "\n",
    "    simparams = {'k': k, 'm': m, 'tau': tau, 'forcefield_param': forcefield_param, 'inertial_param': inertial_param,\n",
    "              'delta': delta, 'rtime': rtime, 'prep_time': prep_time, 'nStep': nStep, 'r': r, \n",
    "              'w_ffdyn': w_ffdyn, \n",
    "              'num_neurons': num_neurons, 'nPrep': nPrep, 'wprep': wprep, 'neuron_tau_net': 20e-3}\n",
    "    \n",
    "    return simparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f003f5a",
   "metadata": {},
   "source": [
    "#### define the function to simulate the reaching control task to 8 different targets ###########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d40f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reach_forcefielddynamics(params):\n",
    "    # GET body matrices and SET cost matrices\n",
    "    system_dynamics= limbNetwork_modifieddynamics(params)\n",
    "    Atot, Btot, Htot = system_dynamics.getSystemMatrices()\n",
    "    #R, Q = setCostmatrices(Atot, Btot, params['delta'], params['r'], params['w']) # cross-checked the R, Q with Fred's code. They are the same\n",
    "    #R, Q = setCostmatrices_wprep(Atot, Btot, params['delta'], params['r'], params['w_ffdyn'], params['wprep'], params['nPrep']) # cross-checked the R, Q with Fred's code. They are the same\n",
    "\n",
    "    # By this point, we have the system matrices (Atot,Btot) and the cost matrices (R,Q). Now we need to compute the feedback gains L.\n",
    "    # For this, we need to compute the noise covariance matrix SigmaXi. We will use the same noise covariance matrix as Fred's code.\n",
    "    # The noise covariance matrix is defined as follows:\n",
    "    SigmaXi = system_dynamics.SigmaXi + 0.0\n",
    "    SigmaOmega = system_dynamics.SigmaOmega + 0.0\n",
    "\n",
    "    R, Q = controllerFuncs.setCostmatrices_wprep_MPC(Atot, Btot, params['delta'], params['r'], params['w_ffdyn'], params['wprep'], params['nPrep'])\n",
    "    L = controllerFuncs.basicLQG(Atot, Btot, Q, R, SigmaXi)\n",
    "    K = controllerFuncs.basicKalman(Atot, Btot, Q, R, Htot, SigmaXi, SigmaOmega)\n",
    "    \n",
    "    system_dynamics.SigmaXi[3,3] = 0                 # X force trick\n",
    "    SigmaXi[3, 3] = 0                 # X force trick\n",
    "\n",
    "\n",
    "    # Now we have the feedback gains L. We can use this to simulate the system.\n",
    "    # For this, we need to define the simulation time and the target parameters\n",
    "    simtime = np.arange(0, params['rtime']+params['prep_time'] + params['delta'], params['delta'])\n",
    "    num_targconditions = 4\n",
    "    num_states = (params['num_neurons'] + 1 + 8) * 3\n",
    "    num_controls = params['num_neurons']\n",
    "    num_steps = len(simtime)\n",
    "    all_states = np.zeros((num_steps, num_targconditions, num_states))\n",
    "    all_estimates = np.zeros((num_steps, num_targconditions, num_states))\n",
    "    all_controls = np.zeros((num_steps, num_targconditions, num_controls))\n",
    "    all_innovation = np.zeros((num_steps, num_targconditions, num_states))\n",
    "    \n",
    "    # targets location is in the indices 8 and 12 for X and Y respectively\n",
    "    # so for 8 conditions, we will use just one vertical target but first 4 conds are unpertuebd movements and the last 4 are perturbed\n",
    "    # the target state is defined as follows:\n",
    "    target_states = np.zeros((num_targconditions, num_states))\n",
    "    target_states[:, 8 + params['num_neurons'] + 1] = 0.0 + 0.0*np.cos(np.arange(0, 2*np.pi, 2*np.pi/num_targconditions))   # X\n",
    "    target_states[:, 12 + params['num_neurons'] + 1] = 0.2 + 0.0*np.sin(np.arange(0, 2*np.pi, 2*np.pi/num_targconditions))  # Y\n",
    "\n",
    "    # target states for preparation\n",
    "    prep_states = np.zeros((num_targconditions, num_states))\n",
    "    prep_states[:, 2 * (8 + params['num_neurons'] + 1)] = 0.0   # X\n",
    "    prep_states[:, 2 * (8 + params['num_neurons'] + 1) + 4] = 0.0   # X\n",
    "\n",
    "    # the target states are active for the entire simulation time\n",
    "    # so the all_states matrix will have the target states repeated for all time steps\n",
    "    all_states[:, :, 8 + params['num_neurons'] + 1] = target_states[:, 8 +params['num_neurons'] + 1].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_states[:, :, 12 + params['num_neurons'] + 1] = target_states[:, 12 + params['num_neurons'] + 1].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_states[:, :, 2 * (8 + params['num_neurons'] + 1)] = prep_states[:, 2 * (8 + params['num_neurons'] + 1)].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_states[:, :, 2 * (8 + params['num_neurons'] + 1) + 4] = prep_states[:, 2 * (8 + params['num_neurons'] + 1) + 4].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_estimates[:, :, 8 + params['num_neurons'] + 1] = target_states[:, 8 + params['num_neurons'] + 1].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_estimates[:, :, 12 + params['num_neurons'] + 1] = target_states[:, 12 + params['num_neurons'] + 1].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_estimates[:, :, 2 * (8 + params['num_neurons'] + 1)] = prep_states[:, 2 * (8 + params['num_neurons'] + 1)].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_estimates[:, :, 2 * (8 + params['num_neurons'] + 1) + 4] = prep_states[:, 2 * (8 + params['num_neurons'] + 1) + 4].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "\n",
    "    # set the desired offset states as 1 for the preparatory and actual target states\n",
    "    all_states[:, :, 8 + params['num_neurons']] = 1.0\n",
    "    all_states[:, :, 2*(8 + params['num_neurons'])] = 0.0\n",
    "    all_states[:, :, 3*(8 + params['num_neurons'])] = 0.0\n",
    "    all_estimates[:, :, 8 + params['num_neurons']] = 1.0\n",
    "    all_estimates[:, :, 2*(8 + params['num_neurons'])] = 0.0\n",
    "    all_estimates[:, :, 3*(8 + params['num_neurons'])] = 0.0\n",
    "\n",
    "    # divide L into L_local and L_body\n",
    "    body_state_indices_range = [[0, 8], [109, 117], [218, 226]]\n",
    "    neural_state_indices_range = [[8, 108], [117, 217], [226, 326]] # excluding the offset variable\n",
    "    # generate a list of indices for the body and neural states\n",
    "    body_state_indices = np.concatenate([np.arange(body_state_indices_range[i][0], body_state_indices_range[i][1]) for i in range(3)])\n",
    "    neural_state_indices = np.concatenate([np.arange(neural_state_indices_range[i][0], neural_state_indices_range[i][1]) for i in range(3)])\n",
    "\n",
    "    # set the all_neuron_components and all_body_components matrices\n",
    "    all_neural_components = np.zeros((num_steps, num_targconditions, len(neural_state_indices)))\n",
    "    all_body_components = np.zeros((num_steps, num_targconditions, len(neural_state_indices)))\n",
    "    all_default_components = np.zeros((num_steps, num_targconditions, len(neural_state_indices))) # for default dynamics\n",
    "    all_net_sys_matrix = np.zeros((num_steps, num_targconditions, len(neural_state_indices), len(neural_state_indices))) # for default dynamics\n",
    "\n",
    "\n",
    "\n",
    "    # run forward simulation\n",
    "    for i in range(num_targconditions):\n",
    "        system_dynamics.reset(all_states[0, i, :])\n",
    "        for t in range(num_steps-1):\n",
    "            # apply mechanical perturbation lateral (OPTIONAL)\n",
    "            if t >= params['nPrep'] + 10 and  t  <= params['nPrep'] + 20   and i == 2:\n",
    "                system_dynamics.states[3] = 0 # setting a non-zero value applies external perturbation for 100 ms \n",
    "\n",
    "            current_state = all_states[t, i, :] + 0.0\n",
    "            #current_estimate = all_estimates[t, i, :] + 0.0\n",
    "\n",
    "            #L = mixedLQG(Atot, Btot, Q[t:t+30, :, :], R[t:t+30, :, :], SigmaXi, params['nPrep'])\n",
    "\n",
    "            # apply control based on current estimate\n",
    "            if t < params['nPrep']:\n",
    "                # prepare until the GO cue is given\n",
    "                current_control = -L[0, :, :] @ current_state\n",
    "            if t >= params['nPrep']:\n",
    "                # unroll the control gains for the movement period\n",
    "                current_control = -L[t - params['nPrep'], :, :] @ current_state\n",
    "            \n",
    "\n",
    "            all_controls[t, i, :] = current_control + 0.0\n",
    "\n",
    "            #update the estimate\n",
    "            #next_estimate, next_innovation = bodyins.nextEstimate(K[t, :, :], current_control)\n",
    "            # update the state\n",
    "            nextState = system_dynamics.nextState(current_control)\n",
    "\n",
    "            # store the states\n",
    "            all_states[t+1, i, :] = nextState + 0.0\n",
    "            \n",
    "            # also decompose the system states into neural and body components and store them\n",
    "            current_neuron_states = current_state[neural_state_indices] + 0\n",
    "            current_body_states = current_state[body_state_indices] + 0\n",
    "            neuron_gains = L[:, :, neural_state_indices] + 0\n",
    "            body_gains = L[:, :, body_state_indices] + 0\n",
    "\n",
    "            \n",
    "\n",
    "            # OPTIONAL CODE: to decompose network dynamics into ongoing and behavioral terms \n",
    "            if t < params['nPrep']:\n",
    "                body_term = -Btot[neural_state_indices, :] @ (body_gains[0,:,:] @ current_body_states) # must be of size (augemnted states x 1)\n",
    "                # compute the (A - B L_local) x_t, forming the first component of the next state\n",
    "                neural_term = (Atot[neural_state_indices, neural_state_indices] - (Btot[neural_state_indices, :] @ neuron_gains[0,:,:])) @ current_neuron_states # must be of size (augmented states x 1)\n",
    "\n",
    "                #neural_term = body_term - ((Btot[neural_state_indices, :] @ neuron_gains[0,:,:]) @ current_neuron_states)\n",
    "                default_term = Atot[neural_state_indices, neural_state_indices] @ current_neuron_states\n",
    "\n",
    "                net_sys_matrix = Atot[neural_state_indices, neural_state_indices] - (Btot[neural_state_indices, :] @ neuron_gains[0,:,:])\n",
    "            else:\n",
    "                body_term = -Btot[neural_state_indices, :] @ (body_gains[t - params['nPrep'],:,:] @ current_body_states)\n",
    "                neural_term = (Atot[neural_state_indices, neural_state_indices] - (Btot[neural_state_indices, :] @ neuron_gains[t - params['nPrep'],:,:])) @ current_neuron_states\n",
    "                \n",
    "                #neural_term = body_term - ((Btot[neural_state_indices, :] @ neuron_gains[t - params['nPrep'],:,:]) @ current_neuron_states)\n",
    "                default_term = Atot[neural_state_indices, neural_state_indices] @ current_neuron_states\n",
    "\n",
    "                net_sys_matrix = Atot[neural_state_indices, neural_state_indices] - (Btot[neural_state_indices, :] @ neuron_gains[t - params['nPrep'],:,:])\n",
    "            # extract the body components from the body_term\n",
    "            all_body_components[t+1, i, :] = body_term + 0\n",
    "            # extract the neuron components from the neural_term\n",
    "            all_neural_components[t+1, i, :] = neural_term + 0\n",
    "            all_default_components[t+1, i, :] = default_term + 0\n",
    "            all_net_sys_matrix[t+1, i, :, :] = net_sys_matrix + 0\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "    results = {}\n",
    "    results['states'] = all_states\n",
    "    results['estimates'] = all_estimates\n",
    "    results['controls'] = all_controls\n",
    "    results['innovations'] = all_innovation\n",
    "    results['L'] = L\n",
    "    results['K'] = K\n",
    "    results['Atot'] = Atot\n",
    "    results['Btot'] = Btot\n",
    "    results['bodyins'] = system_dynamics\n",
    "    results['Htot'] = Htot\n",
    "    results['all_neural_components'] = all_neural_components\n",
    "    results['all_body_components'] = all_body_components\n",
    "    results['all_default_components'] = all_default_components\n",
    "    results['all_net_sys_matrix'] = all_net_sys_matrix\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfddb7a",
   "metadata": {},
   "source": [
    "#### Function to run simulation of an 8 target reaching task once #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c74d4fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## function to run the simulation based on user input (single or batch runs) ##########\n",
    "def run_simulation(args):\n",
    "    spectral_radius = args.spectral_radiuses[0]\n",
    "    networks, readouts = load_networks_by_spectral_radius(args)\n",
    "    network_id = args.network_id + 0\n",
    "\n",
    "\n",
    "    \n",
    "    fflevels = [-5, -2.5, 0.0, 2.5, 5.0] # variation in force field parameter levels\n",
    "    inertiallevels = [1.0, 1.0, 1.0, 1.0, 1.0] # no inertial load variations in the force field task\n",
    "    simparams_ffdyn1 = setsimparams(fflevels[4], inertiallevels[4])\n",
    "    simparams_ffdyn2 = setsimparams(fflevels[3], inertiallevels[3])\n",
    "    simparams_ffdyn3 = setsimparams(fflevels[2], inertiallevels[2])\n",
    "    simparams_ffdyn4 = setsimparams(fflevels[1], inertiallevels[1])\n",
    "    simparams_ffdyn5 = setsimparams(fflevels[0], inertiallevels[0])\n",
    "    \n",
    "    network = networks[network_id]\n",
    "    readout = readouts[network_id]\n",
    "    networkparams = {}\n",
    "    networkparams['Wrec'] = network\n",
    "    networkparams['Wout'] = readout\n",
    "    networkparams['spectral_radius'] = spectral_radius\n",
    "    networkparams['network_id'] = network_id\n",
    "\n",
    "    networkparams['Win'] = np.zeros((networkparams['Wrec'].shape[0], 8))\n",
    "    S = 8\n",
    "    N = networkparams['Wrec'].shape[0]\n",
    "\n",
    "    \n",
    "    simparams_ffdyn1.update(networkparams)\n",
    "    simparams_ffdyn2.update(networkparams)\n",
    "    simparams_ffdyn3.update(networkparams)\n",
    "    simparams_ffdyn4.update(networkparams)\n",
    "    simparams_ffdyn5.update(networkparams)\n",
    "\n",
    "    # run the simulations\n",
    "    results_ffdynlvl1 = reach_forcefielddynamics(simparams_ffdyn1)\n",
    "    results_ffdynlvl2 = reach_forcefielddynamics(simparams_ffdyn2)\n",
    "    results_ffdynlvl3 = reach_forcefielddynamics(simparams_ffdyn3)\n",
    "    results_ffdynlvl4 = reach_forcefielddynamics(simparams_ffdyn4)\n",
    "    results_ffdynlvl5 = reach_forcefielddynamics(simparams_ffdyn5)\n",
    "\n",
    "    return results_ffdynlvl1, results_ffdynlvl2, results_ffdynlvl3, results_ffdynlvl4, results_ffdynlvl5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f298c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## function to save the results in a new hdf5 file ##########\n",
    "def save_results_to_hdf5(filename, results_ffdynlvl1, results_ffdynlvl2, results_ffdynlvl3, results_ffdynlvl4, results_ffdynlvl5, args):\n",
    "    spectral_radius = args.spectral_radiuses[0]\n",
    "    i = args.network_id + 0\n",
    "    with h5py.File(filename, 'a') as f:  # Change 'w' to 'a' to append to the file instead of overwriting\n",
    "            group = f.require_group(str(spectral_radius))  # Use require_group instead of create_group\n",
    "            if f'network_{i}' in group: # check if the group for network i already exists\n",
    "                network_group = group[f'network_{i}']\n",
    "            else:\n",
    "                network_group = group.create_group(f'network_{i}')\n",
    "\n",
    "            # Function to save a dictionary of ndarrays\n",
    "            def save_dict_of_ndarrays(subgroup, data_dict):\n",
    "                for key, value in data_dict.items():\n",
    "                    # Ensure value is an ndarray here; if not, you might need additional handling\n",
    "                    if isinstance(value, np.ndarray):\n",
    "                        subgroup.create_dataset(key, data=value)\n",
    "                    else:\n",
    "                        # Handle non-ndarray data types (e.g., serialize or convert)\n",
    "                        print(f\"Skipping {key}: not an ndarray\")\n",
    "\n",
    "            # Save each results variable\n",
    "            save_dict_of_ndarrays(network_group.create_group('results_ffdynlvl1'), results_ffdynlvl1)\n",
    "            save_dict_of_ndarrays(network_group.create_group('results_ffdynlvl2'), results_ffdynlvl2)\n",
    "            save_dict_of_ndarrays(network_group.create_group('results_ffdynlvl3'), results_ffdynlvl3)\n",
    "            save_dict_of_ndarrays(network_group.create_group('results_ffdynlvl4'), results_ffdynlvl4)\n",
    "            save_dict_of_ndarrays(network_group.create_group('results_ffdynlvl5'), results_ffdynlvl5)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f74c9849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109, 109) (109, 100)\n",
      "(109, 109) (109, 100)\n",
      "(109, 109) (109, 100)\n",
      "(109, 109) (109, 100)\n",
      "(109, 109) (109, 100)\n",
      "Skipping bodyins: not an ndarray\n",
      "Skipping bodyins: not an ndarray\n",
      "Skipping bodyins: not an ndarray\n",
      "Skipping bodyins: not an ndarray\n",
      "Skipping bodyins: not an ndarray\n"
     ]
    }
   ],
   "source": [
    "########## MAIN function that runs the task simulations with 5 random networks ##########\n",
    "\n",
    "##___________________To use the dense RNN without any inhibitory stabilized network structure use the following args___________##\n",
    "#parser = argparse.ArgumentParser(description='Generate dense neural networks with different spectral radiuses and save them to a HDF5 file.')\n",
    "#parser.add_argument('--filename', type=str, default = 'dense_network_weights.hdf5', help='The HDF5 file to save the networks to.')\n",
    "#parser.add_argument('--spectral_radiuses', type=float, nargs='+', default=[0.8], help='The spectral radiuses of the networks.')\n",
    "#parser.add_argument('--seed', type=int, default=0, help='The seed for the random number generator.')\n",
    "#parser.add_argument('--network_id', type=int, default=0, help='The ID of the network to run the simulation for.')\n",
    "#parser.add_argument('--neural_effort_scaling', type=int, default=1e-12, help='The neural effort level. 1 for low, 2 for high.')\n",
    "## In a Jupyter notebook avoid parsing kernel args: use empty list to get defaults\n",
    "#args = parser.parse_args([])\n",
    "## the file should be in the data store directory above the current directory\n",
    "## use only the basename from the provided filename to avoid accidental absolute paths\n",
    "#args.filename = os.path.join('datastore', 'WeightsData', 'denseRNN', os.path.basename(args.filename))\n",
    "#args.neural_effort_scaling = 1\n",
    "#store_data_filename = 'datastore/SimulationData/forcefield_task/denseRNN/denseRNN_results_singlesimulation.hdf5'\n",
    "\n",
    "\n",
    "##___________________To use the inhibitory stabilized network structure use the following args___________##\n",
    "parser = argparse.ArgumentParser(description='Generate ISN neural networks with different spectral radiuses and save them to a HDF5 file.')\n",
    "parser.add_argument('--filename', type=str, default = 'isn_networks.hdf5', help='The HDF5 file to save the networks to.')\n",
    "parser.add_argument('--spectral_radiuses', type=float, nargs='+', default=[0.3], help='The spectral radiuses of the networks.')\n",
    "parser.add_argument('--seed', type=int, default=0, help='The seed for the random number generator.')\n",
    "parser.add_argument('--network_id', type=int, default=0, help='The ID of the network to run the simulation for.')\n",
    "parser.add_argument('--neural_effort_scaling', type=int, default=1e-12, help='The neural effort level. 1 for low, 2 for high.')\n",
    "# In a Jupyter notebook avoid parsing kernel args: use empty list to get defaults\n",
    "args = parser.parse_args([])\n",
    "# the file should be in the data store directory above the current directory\n",
    "# use only the basename from the provided filename to avoid accidental absolute paths\n",
    "args.filename = os.path.join('datastore', 'WeightsData', 'ISN', os.path.basename(args.filename))\n",
    "args.neural_effort_scaling = 1\n",
    "store_data_filename = 'datastore/SimulationData/forcefield_task/denseRNN/denseRNN_results_singlesimulation.hdf5'\n",
    "\t\n",
    "# Run a single simulation\n",
    "args.network_id = 0\n",
    "results_ffdynlvl1, results_ffdynlvl2, results_ffdynlvl3, results_ffdynlvl4, results_ffdynlvl5 = run_simulation(args)\n",
    "# pass the results and args to the save function (correct argument order)\n",
    "save_results_to_hdf5(store_data_filename, results_ffdynlvl1, results_ffdynlvl2, results_ffdynlvl3, results_ffdynlvl4, results_ffdynlvl5, args)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01b8fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8bbb75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c3a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('', '...')))  \n",
    "# Import the required modules\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import h5py\n",
    "import json\n",
    "import argparse\n",
    "from functions.system.limbNetwork import limbNetwork\n",
    "from functions.controller import controllerFuncs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e97286",
   "metadata": {},
   "source": [
    "## Here we will define the simulation parameters \n",
    "\n",
    "This involves \n",
    "1. loading the saved random network (adjacency matrix and readout weights)\n",
    "2. setting the task parameters such as time for preparation and movement, and the penalties on different system states\n",
    "3. setting up cost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2481bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## load Radnomly initialized networks from the hdf5 files ##########\n",
    "def load_networks_by_spectral_radius(args):\n",
    "    filename = args.filename\n",
    "    spectral_radius = args.spectral_radiuses[0] + 0\n",
    "    networks = []\n",
    "    readouts = []\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        spectral_radius_group = str(spectral_radius)  # Ensure the spectral radius is in the correct format\n",
    "        if spectral_radius_group in f:\n",
    "            for i in range(10):  # Assuming there are always 10 networks\n",
    "                network_dataset_name = f'{spectral_radius_group}/networks/network_{i}'\n",
    "                readout_dataset_name = f'{spectral_radius_group}/readouts/readout_{i}'\n",
    "                if network_dataset_name in f:\n",
    "                    network = f[network_dataset_name][()]\n",
    "                    networks.append(network)\n",
    "\n",
    "                    readout = f[readout_dataset_name][()]\n",
    "                    readouts.append(readout)\n",
    "                else:\n",
    "                    print(f\"Dataset {network_dataset_name} not found.\")\n",
    "        else:\n",
    "            print(f\"Spectral radius group {spectral_radius_group} not found.\")\n",
    "    return networks, readouts\n",
    "\n",
    "\n",
    "################# define simulation parameters #####################\n",
    "def setsimparams(widetarget_param, shooting_param):\n",
    "    k = 0.1\n",
    "    m = 1\n",
    "    tau = 0.06\n",
    "    delta = 0.01\n",
    "    rtime = 0.3\n",
    "    prep_time = 1.0\n",
    "\n",
    "    num_neurons = 100\n",
    "    nStep = int(np.round((rtime + prep_time)/delta))\n",
    "    nPrep = int(np.round(prep_time/delta))\n",
    "    nHold = 0\n",
    "    w_execute = np.zeros(shape=(8+num_neurons+1, nStep-nPrep+1))\n",
    "\n",
    "    \n",
    "\n",
    "    #### COSTS parameters by including the neuron_tau_net in B matrix ########\n",
    "    prep_alpha = 1e3\n",
    "    effort_alpha = 1e-12\n",
    "\n",
    "\n",
    "    #### TESTING MORE COSTS ########\n",
    "    prep_alpha = 100\n",
    "    effort_alpha = 1e-11\n",
    "    \n",
    "    for t in range(0, nStep - nPrep):\n",
    "        w_execute[:8, t] = (1/(nStep-nHold)) * np.array([100 * widetarget_param, \n",
    "                                                 0.15 * shooting_param, 0, \n",
    "                                                 0, 100, 0.15 * shooting_param, 0, 0]) * ((t) / (nStep - nPrep))**6\n",
    "        w_execute[:8, t] = (1/(nStep-nHold)) * np.array([200, 0.15 * shooting_param, 0.001 , 0, 200, 0.15 * shooting_param, 0.001, 0]) * ((t) / (nStep - nPrep))**6\n",
    "\n",
    "\n",
    "    wprep = np.zeros(shape=(8+num_neurons+1, nPrep+1))\n",
    "    for t in range(0, nPrep+1):\n",
    "        wprep[:8, t] = (1/nStep) * prep_alpha * np.array([1, 1, 1, 0, 1, 1, 1, 0]) \n",
    "\n",
    "    r = effort_alpha + 0.0\n",
    "\n",
    "\n",
    "    simparams = {'k': k, 'm': m, 'tau': tau, 'widetarget_param': widetarget_param, 'shooting_param': shooting_param,\n",
    "              'delta': delta, 'rtime': rtime, 'prep_time': prep_time, 'nStep': nStep, 'r': r, \n",
    "              'w_ffdyn': w_execute, \n",
    "              'num_neurons': num_neurons, 'nPrep': nPrep, 'wprep': wprep, 'neuron_tau_net': 20e-3}\n",
    "    \n",
    "    return simparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f003f5a",
   "metadata": {},
   "source": [
    "#### define the function to simulate the reaching control task to given number of targets ###########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d40f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reach_ineritalloading(params):\n",
    "    # GET body matrices and SET cost matrices\n",
    "    system_dynamics= limbNetwork(params)\n",
    "    Atot, Btot, Htot = system_dynamics.getSystemMatrices()\n",
    "    #R, Q = setCostmatrices(Atot, Btot, params['delta'], params['r'], params['w']) # cross-checked the R, Q with Fred's code. They are the same\n",
    "    #R, Q = setCostmatrices_wprep(Atot, Btot, params['delta'], params['r'], params['w_ffdyn'], params['wprep'], params['nPrep']) # cross-checked the R, Q with Fred's code. They are the same\n",
    "\n",
    "    # By this point, we have the system matrices (Atot,Btot) and the cost matrices (R,Q). Now we need to compute the feedback gains L.\n",
    "    # For this, we need to compute the noise covariance matrix SigmaXi. We will use the same noise covariance matrix as Fred's code.\n",
    "    # The noise covariance matrix is defined as follows:\n",
    "    SigmaXi = system_dynamics.SigmaXi + 0.0\n",
    "    SigmaOmega = system_dynamics.SigmaOmega + 0.0\n",
    "\n",
    "    R, Q = controllerFuncs.setCostmatrices_wprep_MPC(Atot, Btot, params['delta'], params['r'], params['w_ffdyn'], params['wprep'], params['nPrep'])\n",
    "    L = controllerFuncs.basicLQG(Atot, Btot, Q, R, SigmaXi)\n",
    "    K = controllerFuncs.basicKalman(Atot, Btot, Q, R, Htot, SigmaXi, SigmaOmega)\n",
    "    \n",
    "    system_dynamics.SigmaXi[3,3] = 0                 # X force trick\n",
    "    SigmaXi[3, 3] = 0                 # X force trick\n",
    "\n",
    "\n",
    "    # Now we have the feedback gains L. We can use this to simulate the system.\n",
    "    # For this, we need to define the simulation time and the target parameters\n",
    "    simtime = np.arange(0, params['rtime']+params['prep_time'] + params['delta'], params['delta'])\n",
    "    num_targconditions = 4\n",
    "    num_states = (params['num_neurons'] + 1 + 8) * 3\n",
    "    num_controls = params['num_neurons']\n",
    "    num_steps = len(simtime)\n",
    "    all_states = np.zeros((num_steps, num_targconditions, num_states))\n",
    "    all_estimates = np.zeros((num_steps, num_targconditions, num_states))\n",
    "    all_controls = np.zeros((num_steps, num_targconditions, num_controls))\n",
    "    all_innovation = np.zeros((num_steps, num_targconditions, num_states))\n",
    "    \n",
    "    # targets location is in the indices 8 and 12 for X and Y respectively\n",
    "    # so for 8 conditions, we will use just one vertical target but first 4 conds are unpertuebd movements and the last 4 are perturbed\n",
    "    # the target state is defined as follows:\n",
    "    target_states = np.zeros((num_targconditions, num_states))\n",
    "    target_states[:, 8 + params['num_neurons'] + 1] = 0.0 + 0.0*np.cos(np.arange(0, 2*np.pi, 2*np.pi/num_targconditions))   # X\n",
    "    target_states[:, 12 + params['num_neurons'] + 1] = 0.2 + 0.0*np.sin(np.arange(0, 2*np.pi, 2*np.pi/num_targconditions))  # Y\n",
    "\n",
    "    # target states for preparation\n",
    "    prep_states = np.zeros((num_targconditions, num_states))\n",
    "    prep_states[:, 2 * (8 + params['num_neurons'] + 1)] = 0.0   # X\n",
    "    prep_states[:, 2 * (8 + params['num_neurons'] + 1) + 4] = 0.0   # X\n",
    "\n",
    "    # the target states are active for the entire simulation time\n",
    "    # so the all_states matrix will have the target states repeated for all time steps\n",
    "    all_states[:, :, 8 + params['num_neurons'] + 1] = target_states[:, 8 +params['num_neurons'] + 1].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_states[:, :, 12 + params['num_neurons'] + 1] = target_states[:, 12 + params['num_neurons'] + 1].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_states[:, :, 2 * (8 + params['num_neurons'] + 1)] = prep_states[:, 2 * (8 + params['num_neurons'] + 1)].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_states[:, :, 2 * (8 + params['num_neurons'] + 1) + 4] = prep_states[:, 2 * (8 + params['num_neurons'] + 1) + 4].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_estimates[:, :, 8 + params['num_neurons'] + 1] = target_states[:, 8 + params['num_neurons'] + 1].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_estimates[:, :, 12 + params['num_neurons'] + 1] = target_states[:, 12 + params['num_neurons'] + 1].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_estimates[:, :, 2 * (8 + params['num_neurons'] + 1)] = prep_states[:, 2 * (8 + params['num_neurons'] + 1)].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "    all_estimates[:, :, 2 * (8 + params['num_neurons'] + 1) + 4] = prep_states[:, 2 * (8 + params['num_neurons'] + 1) + 4].reshape((1, num_targconditions)).repeat(num_steps, axis=0)\n",
    "\n",
    "    # set the desired offset states as 1 for the preparatory and actual target states\n",
    "    all_states[:, :, 8 + params['num_neurons']] = 1.0\n",
    "    all_states[:, :, 2*(8 + params['num_neurons'])] = 0.0\n",
    "    all_states[:, :, 3*(8 + params['num_neurons'])] = 0.0\n",
    "    all_estimates[:, :, 8 + params['num_neurons']] = 1.0\n",
    "    all_estimates[:, :, 2*(8 + params['num_neurons'])] = 0.0\n",
    "    all_estimates[:, :, 3*(8 + params['num_neurons'])] = 0.0\n",
    "\n",
    "    # divide L into L_local and L_body\n",
    "    body_state_indices_range = [[0, 8], [109, 117], [218, 226]]\n",
    "    neural_state_indices_range = [[8, 108], [117, 217], [226, 326]] # excluding the offset variable\n",
    "    # generate a list of indices for the body and neural states\n",
    "    body_state_indices = np.concatenate([np.arange(body_state_indices_range[i][0], body_state_indices_range[i][1]) for i in range(3)])\n",
    "    neural_state_indices = np.concatenate([np.arange(neural_state_indices_range[i][0], neural_state_indices_range[i][1]) for i in range(3)])\n",
    "\n",
    "    # set the all_neuron_components and all_body_components matrices\n",
    "    all_neural_components = np.zeros((num_steps, num_targconditions, len(neural_state_indices)))\n",
    "    all_body_components = np.zeros((num_steps, num_targconditions, len(neural_state_indices)))\n",
    "    all_default_components = np.zeros((num_steps, num_targconditions, len(neural_state_indices))) # for default dynamics\n",
    "    all_net_sys_matrix = np.zeros((num_steps, num_targconditions, len(neural_state_indices), len(neural_state_indices))) # for default dynamics\n",
    "\n",
    "\n",
    "\n",
    "    # run forward simulation\n",
    "    for i in range(num_targconditions):\n",
    "        system_dynamics.reset(all_states[0, i, :])\n",
    "        for t in range(num_steps-1):\n",
    "            # apply mechanical perturbation lateral (OPTIONAL)\n",
    "            if t >= params['nPrep'] + 10 and  t  <= params['nPrep'] + 20   and i == 2:\n",
    "                system_dynamics.states[3] = 0 # setting a non-zero value applies external perturbation for 100 ms \n",
    "\n",
    "            current_state = all_states[t, i, :] + 0.0\n",
    "            #current_estimate = all_estimates[t, i, :] + 0.0\n",
    "\n",
    "            #L = mixedLQG(Atot, Btot, Q[t:t+30, :, :], R[t:t+30, :, :], SigmaXi, params['nPrep'])\n",
    "\n",
    "            # apply control based on current estimate\n",
    "            if t < params['nPrep']:\n",
    "                # prepare until the GO cue is given\n",
    "                current_control = -L[0, :, :] @ current_state\n",
    "            if t >= params['nPrep']:\n",
    "                # unroll the control gains for the movement period\n",
    "                current_control = -L[t - params['nPrep'], :, :] @ current_state\n",
    "            \n",
    "\n",
    "            all_controls[t, i, :] = current_control + 0.0\n",
    "\n",
    "            #update the estimate\n",
    "            #next_estimate, next_innovation = bodyins.nextEstimate(K[t, :, :], current_control)\n",
    "            # update the state\n",
    "            nextState = system_dynamics.nextState(current_control)\n",
    "\n",
    "            # store the states\n",
    "            all_states[t+1, i, :] = nextState + 0.0\n",
    "            \n",
    "            # also decompose the system states into neural and body components and store them\n",
    "            current_neuron_states = current_state[neural_state_indices] + 0\n",
    "            current_body_states = current_state[body_state_indices] + 0\n",
    "            neuron_gains = L[:, :, neural_state_indices] + 0\n",
    "            body_gains = L[:, :, body_state_indices] + 0\n",
    "\n",
    "            \n",
    "\n",
    "            # OPTIONAL CODE: to decompose network dynamics into ongoing and behavioral terms \n",
    "            if t < params['nPrep']:\n",
    "                body_term = -Btot[neural_state_indices, :] @ (body_gains[0,:,:] @ current_body_states) # must be of size (augemnted states x 1)\n",
    "                # compute the (A - B L_local) x_t, forming the first component of the next state\n",
    "                neural_term = (Atot[neural_state_indices, neural_state_indices] - (Btot[neural_state_indices, :] @ neuron_gains[0,:,:])) @ current_neuron_states # must be of size (augmented states x 1)\n",
    "\n",
    "                #neural_term = body_term - ((Btot[neural_state_indices, :] @ neuron_gains[0,:,:]) @ current_neuron_states)\n",
    "                default_term = Atot[neural_state_indices, neural_state_indices] @ current_neuron_states\n",
    "\n",
    "                net_sys_matrix = Atot[neural_state_indices, neural_state_indices] - (Btot[neural_state_indices, :] @ neuron_gains[0,:,:])\n",
    "            else:\n",
    "                body_term = -Btot[neural_state_indices, :] @ (body_gains[t - params['nPrep'],:,:] @ current_body_states)\n",
    "                neural_term = (Atot[neural_state_indices, neural_state_indices] - (Btot[neural_state_indices, :] @ neuron_gains[t - params['nPrep'],:,:])) @ current_neuron_states\n",
    "                \n",
    "                #neural_term = body_term - ((Btot[neural_state_indices, :] @ neuron_gains[t - params['nPrep'],:,:]) @ current_neuron_states)\n",
    "                default_term = Atot[neural_state_indices, neural_state_indices] @ current_neuron_states\n",
    "\n",
    "                net_sys_matrix = Atot[neural_state_indices, neural_state_indices] - (Btot[neural_state_indices, :] @ neuron_gains[t - params['nPrep'],:,:])\n",
    "            # extract the body components from the body_term\n",
    "            all_body_components[t+1, i, :] = body_term + 0\n",
    "            # extract the neuron components from the neural_term\n",
    "            all_neural_components[t+1, i, :] = neural_term + 0\n",
    "            all_default_components[t+1, i, :] = default_term + 0\n",
    "            all_net_sys_matrix[t+1, i, :, :] = net_sys_matrix + 0\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "    results = {}\n",
    "    results['states'] = all_states\n",
    "    results['estimates'] = all_estimates\n",
    "    results['controls'] = all_controls\n",
    "    results['innovations'] = all_innovation\n",
    "    results['L'] = L\n",
    "    results['K'] = K\n",
    "    results['Atot'] = Atot\n",
    "    results['Btot'] = Btot\n",
    "    results['bodyins'] = system_dynamics\n",
    "    results['Htot'] = Htot\n",
    "    results['all_neural_components'] = all_neural_components\n",
    "    results['all_body_components'] = all_body_components\n",
    "    results['all_default_components'] = all_default_components\n",
    "    results['all_net_sys_matrix'] = all_net_sys_matrix\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfddb7a",
   "metadata": {},
   "source": [
    "#### Function to run simulation of the reaching task once #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c74d4fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## function to run the simulation based on user input (single or batch runs) ##########\n",
    "def run_simulation(args):\n",
    "    spectral_radius = args.spectral_radiuses[0]\n",
    "    networks, readouts = load_networks_by_spectral_radius(args)\n",
    "    network_id = args.network_id + 0\n",
    "\n",
    "\n",
    "    \n",
    "    widetarget_levels = [1, 1, 1, 1, 1] # \n",
    "    shooting_levels = [0, 25, 50, 75, 100] # \n",
    "    shooting_levels = [0, 2.5, 5, 7.5, 10]\n",
    "    simparams_context1 = setsimparams(widetarget_levels[4], shooting_levels[4])\n",
    "    simparams_context2 = setsimparams(widetarget_levels[3], shooting_levels[3])\n",
    "    simparams_context3 = setsimparams(widetarget_levels[2], shooting_levels[2])\n",
    "    simparams_context4 = setsimparams(widetarget_levels[1], shooting_levels[1])\n",
    "    simparams_context5 = setsimparams(widetarget_levels[0], shooting_levels[0])\n",
    "    \n",
    "    network = networks[network_id]\n",
    "    readout = readouts[network_id]\n",
    "    networkparams = {}\n",
    "    networkparams['Wrec'] = network\n",
    "    networkparams['Wout'] = readout\n",
    "    networkparams['spectral_radius'] = spectral_radius\n",
    "    networkparams['network_id'] = network_id\n",
    "\n",
    "    networkparams['Win'] = np.zeros((networkparams['Wrec'].shape[0], 8))\n",
    "    S = 8\n",
    "    N = networkparams['Wrec'].shape[0]\n",
    "\n",
    "    \n",
    "    simparams_context1.update(networkparams)\n",
    "    simparams_context2.update(networkparams)\n",
    "    simparams_context3.update(networkparams)\n",
    "    simparams_context4.update(networkparams)\n",
    "    simparams_context5.update(networkparams)\n",
    "\n",
    "    # run the simulations\n",
    "    results_shootarget_lvl1 = reach_ineritalloading(simparams_context1)\n",
    "    results_shootarget_lvl2 = reach_ineritalloading(simparams_context2)\n",
    "    results_shootarget_lvl3 = reach_ineritalloading(simparams_context3)\n",
    "    results_shootarget_lvl4 = reach_ineritalloading(simparams_context4)\n",
    "    results_shootarget_lvl5 = reach_ineritalloading(simparams_context5)\n",
    "    return results_shootarget_lvl1, results_shootarget_lvl2, results_shootarget_lvl3, results_shootarget_lvl4, results_shootarget_lvl5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f298c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## function to save the results in a new hdf5 file ##########\n",
    "def save_results_to_hdf5(filename, results_shootarget_lvl1, results_shootarget_lvl2, results_shootarget_lvl3, results_shootarget_lvl4, results_shootarget_lvl5, args):\n",
    "    spectral_radius = args.spectral_radiuses[0]\n",
    "    i = args.network_id + 0\n",
    "    with h5py.File(filename, 'a') as f:  # Change 'w' to 'a' to append to the file instead of overwriting\n",
    "            group = f.require_group(str(spectral_radius))  # Use require_group instead of create_group\n",
    "            if f'network_{i}' in group: # check if the group for network i already exists\n",
    "                network_group = group[f'network_{i}']\n",
    "            else:\n",
    "                network_group = group.create_group(f'network_{i}')\n",
    "\n",
    "            # Function to save a dictionary of ndarrays\n",
    "            def save_dict_of_ndarrays(subgroup, data_dict):\n",
    "                for key, value in data_dict.items():\n",
    "                    # Ensure value is an ndarray here; if not, you might need additional handling\n",
    "                    if isinstance(value, np.ndarray):\n",
    "                        subgroup.create_dataset(key, data=value)\n",
    "                    else:\n",
    "                        # Handle non-ndarray data types (e.g., serialize or convert)\n",
    "                        print(f\"Skipping {key}: not an ndarray\")\n",
    "\n",
    "            # Save each results variable\n",
    "            save_dict_of_ndarrays(network_group.create_group('results_shootarget_lvl1'), results_shootarget_lvl1)\n",
    "            save_dict_of_ndarrays(network_group.create_group('results_shootarget_lvl2'), results_shootarget_lvl2)\n",
    "            save_dict_of_ndarrays(network_group.create_group('results_shootarget_lvl3'), results_shootarget_lvl3)\n",
    "            save_dict_of_ndarrays(network_group.create_group('results_shootarget_lvl4'), results_shootarget_lvl4)\n",
    "            save_dict_of_ndarrays(network_group.create_group('results_shootarget_lvl5'), results_shootarget_lvl5)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74c9849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109, 109) (109, 100)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 50\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m##___________________To use the dense RNN without any inhibitory stabilized network structure use the following args___________##\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#parser = argparse.ArgumentParser(description='Generate dense neural networks with different spectral radiuses and save them to a HDF5 file.')\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#parser.add_argument('--filename', type=str, default = 'dense_network_weights.hdf5', help='The HDF5 file to save the networks to.')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Run a single simulation\u001b[39;00m\n\u001b[1;32m     49\u001b[0m args\u001b[38;5;241m.\u001b[39mnetwork_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 50\u001b[0m results_shootarget_lvl1, results_shootarget_lvl2, results_shootarget_lvl3, results_shootarget_lvl4, results_shootarget_lvl5 \u001b[38;5;241m=\u001b[39m run_simulation(args)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# pass the results and args to the save function (correct argument order)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m save_results_to_hdf5(store_data_filename, results_shootarget_lvl1, results_shootarget_lvl2, results_shootarget_lvl3, results_shootarget_lvl4, results_shootarget_lvl5, args)\n",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m, in \u001b[0;36mrun_simulation\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     35\u001b[0m simparams_context5\u001b[38;5;241m.\u001b[39mupdate(networkparams)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# run the simulations\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m results_shootarget_lvl1 \u001b[38;5;241m=\u001b[39m reach_ineritalloading(simparams_context1)\n\u001b[1;32m     39\u001b[0m results_shootarget_lvl2 \u001b[38;5;241m=\u001b[39m reach_ineritalloading(simparams_context2)\n\u001b[1;32m     40\u001b[0m results_shootarget_lvl3 \u001b[38;5;241m=\u001b[39m reach_ineritalloading(simparams_context3)\n",
      "Cell \u001b[0;32mIn[3], line 107\u001b[0m, in \u001b[0;36mreach_ineritalloading\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    102\u001b[0m all_controls[t, i, :] \u001b[38;5;241m=\u001b[39m current_control \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m#update the estimate\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m#next_estimate, next_innovation = bodyins.nextEstimate(K[t, :, :], current_control)\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# update the state\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m nextState \u001b[38;5;241m=\u001b[39m system_dynamics\u001b[38;5;241m.\u001b[39mnextState(current_control)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# store the states\u001b[39;00m\n\u001b[1;32m    110\u001b[0m all_states[t\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, i, :] \u001b[38;5;241m=\u001b[39m nextState \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-RadboudUniversiteit/Documents/GITReps/simulateLQRNetworks/functions/system/limbNetwork.py:120\u001b[0m, in \u001b[0;36mlimbNetwork.nextState\u001b[0;34m(self, Tor)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnextState\u001b[39m(\u001b[38;5;28mself\u001b[39m, Tor): \u001b[38;5;66;03m# Tor is supposed to be torques (xtorque; ytorque)\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# Here we take Torques as inputs and compute the state update using (x_dot = A*x + B*Tor)\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     xi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mmultivariate_normal(np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAtot\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSigmaXi, tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m)\n\u001b[1;32m    121\u001b[0m     cur_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m# updating next state with the naive method - CAUTION when using with network dynamics! \u001b[39;00m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m#next_state = (self.Atot @ cur_state) + (self.Btot @ Tor) + xi.T\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# updating the next state using better continuous differential equ. solvers (ss, odeint etc.,)\u001b[39;00m\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:4261\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.multivariate_normal\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/numpy/linalg/_linalg.py:1839\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1835\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call\u001b[38;5;241m=\u001b[39m_raise_linalgerror_svd_nonconvergence,\n\u001b[1;32m   1837\u001b[0m               invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m, over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1838\u001b[0m               under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m-> 1839\u001b[0m     u, s, vh \u001b[38;5;241m=\u001b[39m gufunc(a, signature\u001b[38;5;241m=\u001b[39msignature)\n\u001b[1;32m   1840\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1841\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########## MAIN function that runs the task simulations (this example script runs one random newtork) ##########\n",
    "\n",
    "\n",
    "##___________________To use the inhibitory stabilized network structure use the following args___________##\n",
    "parser = argparse.ArgumentParser(description='Generate ISN neural networks with different spectral radiuses and save them to a HDF5 file.')\n",
    "parser.add_argument('--filename', type=str, default = 'isn_networks.hdf5', help='The HDF5 file to save the networks to.')\n",
    "\n",
    "#_________define the spectral radius or variance parameter for random connectivity___________#\n",
    "# CAUTION: Note that for denseRNNs, although we call this parameter as spectral_radiuses, it is actually the variance scaling factor 'g'\n",
    "# If using denseRNNs, set this value to 0.8 to load from existing datastore files\n",
    "parser.add_argument('--spectral_radiuses', type=float, nargs='+', default=[0.3], help='The spectral radiuses of the networks.')\n",
    "\n",
    "parser.add_argument('--seed', type=int, default=0, help='The seed for the random number generator.')\n",
    "parser.add_argument('--network_id', type=int, default=0, help='The ID of the network to run the simulation for.')\n",
    "parser.add_argument('--neural_effort_scaling', type=int, default=1e-12, help='The neural effort level. 1 for low, 2 for high.')\n",
    "# In a Jupyter notebook avoid parsing kernel args: use empty list to get defaults\n",
    "args = parser.parse_args([])\n",
    "# the file should be in the data store directory above the current directory\n",
    "# use only the basename from the provided filename to avoid accidental absolute paths\n",
    "args.filename = os.path.join('datastore', 'WeightsData', 'ISN', os.path.basename(args.filename))\n",
    "args.neural_effort_scaling = 1\n",
    "store_data_filename = 'datastore/SimulationData/shootarget_task/denseRNN/denseRNN_results_singlesimulation.hdf5'\n",
    "\n",
    "\n",
    "##___________________To use the dense RNN without any inhibitory stabilized network structure use the following args___________##\n",
    "#parser = argparse.ArgumentParser(description='Generate dense neural networks with different spectral radiuses and save them to a HDF5 file.')\n",
    "#parser.add_argument('--filename', type=str, default = 'dense_network_weights.hdf5', help='The HDF5 file to save the networks to.')\n",
    "\n",
    "##_________define the spectral radius or variance parameter for random connectivity___________#\n",
    "## CAUTION: Note that for denseRNNs, although we call this parameter as spectral_radiuses, it is actually the variance scaling factor 'g'\n",
    "## If using denseRNNs, set this value to 0.8 to load from existing datastore files\n",
    "#parser.add_argument('--spectral_radiuses', type=float, nargs='+', default=[0.8], help='The spectral radiuses of the networks.')\n",
    "\n",
    "#parser.add_argument('--seed', type=int, default=0, help='The seed for the random number generator.')\n",
    "#parser.add_argument('--network_id', type=int, default=0, help='The ID of the network to run the simulation for.')\n",
    "#parser.add_argument('--neural_effort_scaling', type=int, default=1e-12, help='The neural effort level. 1 for low, 2 for high.')\n",
    "## In a Jupyter notebook avoid parsing kernel args: use empty list to get defaults\n",
    "#args = parser.parse_args([])\n",
    "## the file should be in the data store directory above the current directory\n",
    "## use only the basename from the provided filename to avoid accidental absolute paths\n",
    "#args.filename = os.path.join('datastore', 'WeightsData', 'denseRNN', os.path.basename(args.filename))\n",
    "#args.neural_effort_scaling = 1\n",
    "#store_data_filename = 'datastore/SimulationData/shootarget_task/denseRNN/denseRNN_results_singlesimulation.hdf5'\n",
    "\t\n",
    "\n",
    "\n",
    "\n",
    "# Run a single simulation\n",
    "args.network_id = 0\n",
    "results_shootarget_lvl1, results_shootarget_lvl2, results_shootarget_lvl3, results_shootarget_lvl4, results_shootarget_lvl5 = run_simulation(args)\n",
    "# pass the results and args to the save function (correct argument order)\n",
    "save_results_to_hdf5(store_data_filename, results_shootarget_lvl1, results_shootarget_lvl2, results_shootarget_lvl3, results_shootarget_lvl4, results_shootarget_lvl5, args)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a9784",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01b8fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8bbb75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
